{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21981,"status":"ok","timestamp":1684121388765,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"rNkKcVet869G","outputId":"d91fbc65-ac57-4a3b-ba61-5c557031d3ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"rNkKcVet869G"},{"cell_type":"code","execution_count":2,"metadata":{"id":"7d4f9866","executionInfo":{"status":"ok","timestamp":1684121438335,"user_tz":-600,"elapsed":3,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt"],"id":"7d4f9866"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2242,"status":"ok","timestamp":1684121442968,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"6714a84a","outputId":"cafbf6a0-9e56-4469-8750-b6d2948dd736"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             comment  toxic  severe_toxic  \\\n","0  Explanation\\nWhy the edits made under my usern...      0             0   \n","1  D'aww! He matches this background colour I'm s...      0             0   \n","2  Hey man, I'm really not trying to edit war. It...      0             0   \n","3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n","4  You, sir, are my hero. Any chance you remember...      0             0   \n","\n","   obscene  threat  insult  identity_hate  \n","0        0       0       0              0  \n","1        0       0       0              0  \n","2        0       0       0              0  \n","3        0       0       0              0  \n","4        0       0       0              0  "],"text/html":["\n","  <div id=\"df-ab701c7f-4272-4e3c-92a9-5401fea6b586\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab701c7f-4272-4e3c-92a9-5401fea6b586')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ab701c7f-4272-4e3c-92a9-5401fea6b586 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ab701c7f-4272-4e3c-92a9-5401fea6b586');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["df = pd.read_csv(\"/content/drive/MyDrive/Redback_A/toxic.csv\")\n","df = df.drop(\"id\", axis=1)\n","df.columns = ['comment', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","df.head()"],"id":"6714a84a"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684121445931,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"6TxZN4Bcav4z","outputId":"c7a26543-72be-4ccd-fd22-073734400e06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of toxic comments 16225\n","Number of clean comments 143346\n"]}],"source":["## The data is very imbalanced\n","classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","toxic_comments = df[df[classes].sum(axis=1)>0]\n","clean_comments = df[df[classes].sum(axis=1)==0]\n","\n","print(\"Number of toxic comments\", len(toxic_comments))\n","print(\"Number of clean comments\", len(clean_comments))"],"id":"6TxZN4Bcav4z"},{"cell_type":"code","execution_count":5,"metadata":{"id":"AHW429uxbJqj","executionInfo":{"status":"ok","timestamp":1684121449520,"user_tz":-600,"elapsed":2,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}}},"outputs":[],"source":["## Sample clean comments and make dataset balanced\n","uniform_dataset = pd.concat([toxic_comments, clean_comments.sample(len(toxic_comments))])"],"id":"AHW429uxbJqj"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1684121452265,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"PXw1TB2ybbsS","outputId":"e97dd9fd-ea89-424f-84d8-1f2faf934cc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of toxic comments 16225\n","Number of clean comments 16225\n"]}],"source":["## The data is now balanced\n","toxic_comments = uniform_dataset[uniform_dataset[classes].sum(axis=1)>0]\n","clean_comments = uniform_dataset[uniform_dataset[classes].sum(axis=1)==0]\n","\n","print(\"Number of toxic comments\", len(toxic_comments))\n","print(\"Number of clean comments\", len(clean_comments))"],"id":"PXw1TB2ybbsS"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11658,"status":"ok","timestamp":1684121468259,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"4bcrGUV6j_jE","outputId":"e0a61b37-aecc-47f1-937a-d5052cb24e4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"]}],"source":["!pip install transformers"],"id":"4bcrGUV6j_jE"},{"cell_type":"code","execution_count":19,"metadata":{"id":"dyqOqV7Mj6yD","executionInfo":{"status":"ok","timestamp":1684123793168,"user_tz":-600,"elapsed":307,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}}},"outputs":[],"source":["import torch\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(uniform_dataset[\"comment\"], uniform_dataset.drop(\"comment\", axis=1), test_size=0.3, random_state=42)"],"id":"dyqOqV7Mj6yD"},{"cell_type":"code","execution_count":20,"metadata":{"id":"DMA4skpwlAB7","executionInfo":{"status":"ok","timestamp":1684123841996,"user_tz":-600,"elapsed":47058,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}}},"outputs":[],"source":["# Tokenize the text data using BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","X_train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n","X_test_encodings = tokenizer(list(X_test), truncation=True, padding=True)"],"id":"DMA4skpwlAB7"},{"cell_type":"code","execution_count":21,"metadata":{"id":"SZDfn3wLlCV6","executionInfo":{"status":"ok","timestamp":1684123892784,"user_tz":-600,"elapsed":2882,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}}},"outputs":[],"source":["# Convert the encoded features and labels into PyTorch tensors\n","X_train_input_ids = torch.tensor(X_train_encodings['input_ids'])\n","X_train_attention_mask = torch.tensor(X_train_encodings['attention_mask'])\n","y_train = torch.tensor(y_train.values, dtype=torch.float32)\n","\n","X_test_input_ids = torch.tensor(X_test_encodings['input_ids'])\n","X_test_attention_mask = torch.tensor(X_test_encodings['attention_mask'])\n","y_test = torch.tensor(y_test.values, dtype=torch.float32)"],"id":"SZDfn3wLlCV6"},{"cell_type":"code","execution_count":11,"metadata":{"id":"OUHiTDxSlEYH","executionInfo":{"status":"ok","timestamp":1684122503433,"user_tz":-600,"elapsed":326,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}}},"outputs":[],"source":["# Create a PyTorch DataLoader object for training and testing data\n","train_dataset = TensorDataset(X_train_input_ids, X_train_attention_mask, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","test_dataset = TensorDataset(X_test_input_ids, X_test_attention_mask, y_test)\n","test_loader = DataLoader(test_dataset, batch_size=16)"],"id":"OUHiTDxSlEYH"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":962,"referenced_widgets":["50758c6d23694a369d790388f66c030f","a15ca68235ab4dfcbbc7a7b2f1f96509","3c9843248b584372931d09f0fdaad54f","1e381afcce1b4459b4001f2ff476cb0b","bb874a1c491e460898fbfe97f73a4699","70d09ea4b65e433a90c6294fd1460102","7564c18c87764b0c98d3d49bd9038724","77910f58ed254ab1bd4c434e8b14c43d","b63ee23a5b5f4bdcaa4e8e0691212ce9","52d2afe4e0e54b29b8e8c995797674c3","8b062fc55d124aafb34fbaa72df41633"]},"executionInfo":{"elapsed":21702,"status":"ok","timestamp":1684122529188,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"YJ5v8O5JlGIM","outputId":"d0dced28-1074-4f61-a8d3-430f0724b68d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50758c6d23694a369d790388f66c030f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":12}],"source":["# Create a BERT-based multilabel classification model\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"id":"YJ5v8O5JlGIM"},{"cell_type":"code","source":["# Count the number of batches in train_loader\n","import math\n","\n","batch_size = 16  # set the batch size\n","\n","num_batches = math.ceil(len(train_dataset) / batch_size)\n","print(f\"Number of batches in train_loader: {num_batches}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T75nBFpf0zbq","executionInfo":{"status":"ok","timestamp":1683876996014,"user_tz":-600,"elapsed":5,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"}},"outputId":"564132d3-582a-46d8-8f4d-940a39e97155"},"id":"T75nBFpf0zbq","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of batches in train_loader: 1420\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279489,"status":"ok","timestamp":1683876494159,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"Dl4Ckhr3lH-t","outputId":"1f9f6b18-e17b-4ea0-9b9b-686ca404ac8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Batch loss: 0.2802700400352478\n","Batch loss: 0.3621496558189392\n","Batch loss: 0.3402864336967468\n","Batch loss: 0.26903846859931946\n","Batch loss: 0.2913309931755066\n","Batch loss: 0.369019091129303\n","Batch loss: 0.35422438383102417\n","Batch loss: 0.3161960244178772\n","Batch loss: 0.29932448267936707\n","Batch loss: 0.41158199310302734\n","Batch loss: 0.3162040412425995\n","Batch loss: 0.25558599829673767\n","Batch loss: 0.45366621017456055\n","Batch loss: 0.31916430592536926\n","Batch loss: 0.3264186382293701\n","Batch loss: 0.178269624710083\n","Batch loss: 0.26376351714134216\n","Batch loss: 0.3049768805503845\n","Batch loss: 0.3110998272895813\n","Batch loss: 0.1802365481853485\n","Batch loss: 0.2746927738189697\n","Batch loss: 0.26433566212654114\n","Batch loss: 0.2976924180984497\n","Batch loss: 0.2231234312057495\n","Batch loss: 0.26237452030181885\n","Batch loss: 0.20801937580108643\n","Batch loss: 0.19453683495521545\n","Batch loss: 0.28710731863975525\n","Batch loss: 0.32890570163726807\n","Batch loss: 0.26715904474258423\n","Batch loss: 0.26265597343444824\n","Batch loss: 0.2123187780380249\n","Batch loss: 0.3443336486816406\n","Batch loss: 0.22998106479644775\n","Batch loss: 0.3019581437110901\n","Batch loss: 0.22968070209026337\n","Batch loss: 0.246887668967247\n","Batch loss: 0.2214689701795578\n","Batch loss: 0.24337077140808105\n","Batch loss: 0.2535770833492279\n","Batch loss: 0.22030490636825562\n","Batch loss: 0.2269894778728485\n","Batch loss: 0.24477224051952362\n","Batch loss: 0.14099591970443726\n","Batch loss: 0.2930101156234741\n","Batch loss: 0.18300661444664001\n","Batch loss: 0.23305337131023407\n","Batch loss: 0.22712191939353943\n","Batch loss: 0.22823652625083923\n","Batch loss: 0.18266181647777557\n","Batch loss: 0.25807273387908936\n","Batch loss: 0.18781106173992157\n","Batch loss: 0.20810860395431519\n","Batch loss: 0.26196229457855225\n","Batch loss: 0.20860767364501953\n","Batch loss: 0.38382792472839355\n","Batch loss: 0.21526852250099182\n","Batch loss: 0.22676488757133484\n","Batch loss: 0.27115362882614136\n","Batch loss: 0.24856612086296082\n","Batch loss: 0.14083048701286316\n","Batch loss: 0.18607795238494873\n","Batch loss: 0.20333747565746307\n","Batch loss: 0.33547407388687134\n","Batch loss: 0.1806202232837677\n","Batch loss: 0.18928126990795135\n","Batch loss: 0.15363620221614838\n","Batch loss: 0.19993631541728973\n","Batch loss: 0.26144441962242126\n","Batch loss: 0.163417786359787\n","Batch loss: 0.20788025856018066\n","Batch loss: 0.18488121032714844\n","Batch loss: 0.1311863213777542\n","Batch loss: 0.13340801000595093\n","Batch loss: 0.2152092158794403\n","Batch loss: 0.2445344179868698\n","Batch loss: 0.18903987109661102\n","Batch loss: 0.25973570346832275\n","Batch loss: 0.16676728427410126\n","Batch loss: 0.22536568343639374\n","Batch loss: 0.1905248463153839\n","Batch loss: 0.2531019449234009\n","Batch loss: 0.21200820803642273\n","Batch loss: 0.21896913647651672\n","Batch loss: 0.2773805260658264\n","Batch loss: 0.1120087057352066\n","Batch loss: 0.1701829433441162\n","Batch loss: 0.17932038009166718\n","Batch loss: 0.2495095580816269\n","Batch loss: 0.3140541613101959\n","Batch loss: 0.20934878289699554\n","Batch loss: 0.20913830399513245\n","Batch loss: 0.16501310467720032\n","Batch loss: 0.2592662274837494\n","Batch loss: 0.2403019666671753\n","Batch loss: 0.184437558054924\n","Batch loss: 0.16024020314216614\n","Batch loss: 0.24941961467266083\n","Batch loss: 0.28629717230796814\n","Batch loss: 0.19172441959381104\n","Batch loss: 0.09148278832435608\n","Batch loss: 0.15602731704711914\n","Batch loss: 0.2031664103269577\n","Batch loss: 0.14233070611953735\n","Batch loss: 0.1957293003797531\n","Batch loss: 0.18594631552696228\n","Batch loss: 0.2935585379600525\n","Batch loss: 0.20548824965953827\n","Batch loss: 0.15145207941532135\n","Batch loss: 0.27268609404563904\n","Batch loss: 0.2501809597015381\n","Batch loss: 0.22368264198303223\n","Batch loss: 0.22305935621261597\n","Batch loss: 0.17838214337825775\n","Batch loss: 0.2564653754234314\n","Batch loss: 0.25938892364501953\n","Batch loss: 0.26547229290008545\n","Batch loss: 0.15518973767757416\n","Batch loss: 0.1564883142709732\n","Batch loss: 0.2787679433822632\n","Batch loss: 0.15775063633918762\n","Batch loss: 0.1563902050256729\n","Batch loss: 0.2995258867740631\n","Batch loss: 0.1505400836467743\n","Batch loss: 0.17296916246414185\n","Batch loss: 0.1500689834356308\n","Batch loss: 0.18505394458770752\n","Batch loss: 0.20413288474082947\n","Batch loss: 0.17241746187210083\n","Batch loss: 0.11253925412893295\n","Batch loss: 0.17635342478752136\n","Batch loss: 0.13188546895980835\n","Batch loss: 0.1870967447757721\n","Batch loss: 0.35228508710861206\n","Batch loss: 0.21314716339111328\n","Batch loss: 0.15529444813728333\n","Batch loss: 0.2191094607114792\n","Batch loss: 0.16837629675865173\n","Batch loss: 0.22245490550994873\n","Batch loss: 0.15129230916500092\n","Batch loss: 0.200429767370224\n","Batch loss: 0.22034482657909393\n","Batch loss: 0.17721238732337952\n","Batch loss: 0.2161118984222412\n","Batch loss: 0.23850548267364502\n","Batch loss: 0.1952190101146698\n","Batch loss: 0.15359635651111603\n","Batch loss: 0.16672953963279724\n","Batch loss: 0.3399408757686615\n","Batch loss: 0.19391360878944397\n","Batch loss: 0.1673869490623474\n","Batch loss: 0.20823387801647186\n","Batch loss: 0.27850037813186646\n","Batch loss: 0.22569231688976288\n","Batch loss: 0.2650511562824249\n","Batch loss: 0.16976718604564667\n","Batch loss: 0.1924206018447876\n","Batch loss: 0.3529300391674042\n","Batch loss: 0.22372953593730927\n","Batch loss: 0.1968233585357666\n","Batch loss: 0.26193296909332275\n","Batch loss: 0.28953030705451965\n","Batch loss: 0.2693510055541992\n","Batch loss: 0.11464022099971771\n","Batch loss: 0.15741278231143951\n","Batch loss: 0.22626933455467224\n","Batch loss: 0.12863793969154358\n","Batch loss: 0.17899809777736664\n","Batch loss: 0.311006635427475\n","Batch loss: 0.17595729231834412\n","Batch loss: 0.08884930610656738\n","Batch loss: 0.12116830050945282\n","Batch loss: 0.23187005519866943\n","Batch loss: 0.15311965346336365\n","Batch loss: 0.2039492130279541\n","Batch loss: 0.21141600608825684\n","Batch loss: 0.2375059425830841\n","Batch loss: 0.20683453977108002\n","Batch loss: 0.22694778442382812\n","Batch loss: 0.1929626762866974\n","Batch loss: 0.1148356944322586\n","Batch loss: 0.21854709088802338\n","Batch loss: 0.29900723695755005\n","Batch loss: 0.14549872279167175\n","Batch loss: 0.13653704524040222\n","Batch loss: 0.0982140451669693\n","Batch loss: 0.1283154934644699\n","Batch loss: 0.18545298278331757\n","Batch loss: 0.16376712918281555\n","Batch loss: 0.2714899778366089\n","Batch loss: 0.14850085973739624\n","Batch loss: 0.18350276350975037\n","Batch loss: 0.16415366530418396\n","Batch loss: 0.24768754839897156\n","Batch loss: 0.28058287501335144\n","Batch loss: 0.19691157341003418\n","Batch loss: 0.14193777740001678\n","Batch loss: 0.15707091987133026\n","Batch loss: 0.1498025357723236\n","Batch loss: 0.1774582713842392\n"]}],"source":["import random\n","import torch\n","import torch.nn as nn\n","\n","# Train the model using a suitable optimizer and loss function\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 1\n","batch_size = 16\n","train_subset_size = 200  # number of batches to use for training\n","random_seed = 42  # set a random seed for reproducibility\n","\n","model.train()\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# set the random seed\n","random.seed(random_seed)\n","\n","# convert train_loader to a list of batches\n","train_batches = list(train_loader)\n","\n","for epoch in range(num_epochs):\n","    # randomly select a subset of batches for training\n","    train_subset = random.sample(train_batches, train_subset_size)\n","    \n","    for batch in train_subset:\n","        input_ids = batch[0].to(device)\n","        attention_mask = batch[1].to(device)\n","        labels = batch[2].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # get the model outputs\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","\n","        # get the logits and labels tensors\n","        logits = outputs.logits\n","        labels = labels.float()\n","\n","        # compute the loss\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print the average loss for the current batch\n","        print(f\"Batch loss: {loss.mean().item()}\")"],"id":"Dl4Ckhr3lH-t"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiKGVwL3pVbd"},"outputs":[],"source":["# Set the model to evaluation mode\n","model.eval()\n","\n","# Create empty lists for storing true labels and predicted labels\n","true_labels = []\n","pred_labels = []\n","\n","# Iterate through the test data and make predictions\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch[0].to(device)\n","        attention_mask = batch[1].to(device)\n","        labels = batch[2].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","\n","        # Convert the logits to probabilities and round off to 0 or 1\n","        probs = torch.sigmoid(outputs.logits)\n","        preds = (probs >= 0.5).float()\n","\n","        true_labels.extend(labels.cpu().detach().numpy().tolist())\n","        pred_labels.extend(preds.cpu().detach().numpy().tolist())"],"id":"fiKGVwL3pVbd"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":294,"status":"ok","timestamp":1683876966753,"user":{"displayName":"Tianqi Liang","userId":"14034728509150319824"},"user_tz":-600},"id":"ZVTgJXPsIYvh","outputId":"91cd535c-a7f8-4d6b-9843-599a92387fce","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6707755521314843\n","Precision: 0.7722517730496454\n","Recall: 0.8273340298223952\n","F1 score: 0.7988445137328625\n"]}],"source":["# Calculate evaluation metrics\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","accuracy = accuracy_score(true_labels, pred_labels)\n","precision = precision_score(true_labels, pred_labels, average='micro')\n","recall = recall_score(true_labels, pred_labels, average='micro')\n","f1 = f1_score(true_labels, pred_labels, average='micro')\n","\n","print('Accuracy:', accuracy)\n","print('Precision:', precision)\n","print('Recall:', recall)\n","print('F1 score:', f1)"],"id":"ZVTgJXPsIYvh"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"widgets":{"application/vnd.jupyter.widget-state+json":{"50758c6d23694a369d790388f66c030f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a15ca68235ab4dfcbbc7a7b2f1f96509","IPY_MODEL_3c9843248b584372931d09f0fdaad54f","IPY_MODEL_1e381afcce1b4459b4001f2ff476cb0b"],"layout":"IPY_MODEL_bb874a1c491e460898fbfe97f73a4699"}},"a15ca68235ab4dfcbbc7a7b2f1f96509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70d09ea4b65e433a90c6294fd1460102","placeholder":"​","style":"IPY_MODEL_7564c18c87764b0c98d3d49bd9038724","value":"Downloading pytorch_model.bin: 100%"}},"3c9843248b584372931d09f0fdaad54f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77910f58ed254ab1bd4c434e8b14c43d","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b63ee23a5b5f4bdcaa4e8e0691212ce9","value":440473133}},"1e381afcce1b4459b4001f2ff476cb0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52d2afe4e0e54b29b8e8c995797674c3","placeholder":"​","style":"IPY_MODEL_8b062fc55d124aafb34fbaa72df41633","value":" 440M/440M [00:14&lt;00:00, 29.3MB/s]"}},"bb874a1c491e460898fbfe97f73a4699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70d09ea4b65e433a90c6294fd1460102":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7564c18c87764b0c98d3d49bd9038724":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77910f58ed254ab1bd4c434e8b14c43d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b63ee23a5b5f4bdcaa4e8e0691212ce9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52d2afe4e0e54b29b8e8c995797674c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b062fc55d124aafb34fbaa72df41633":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}