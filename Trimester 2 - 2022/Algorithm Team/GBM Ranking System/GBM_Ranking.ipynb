{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading library"
      ],
      "metadata": {
        "id": "tORn0OLUD3UZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N2vWMLWDpBE"
      },
      "outputs": [],
      "source": [
        "from lightgbm.sklearn import LGBMRanker\n",
        "from datetime import timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading all data"
      ],
      "metadata": {
        "id": "9iMXBoSPD6BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_features = pd.read_parquet('../input/ranking-features/user_features.parquet')\n",
        "item_features = pd.read_parquet('../input/ranking-features/item_features.parquet')\n",
        "transactions_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv')\n",
        "transactions_df.t_dat = pd.to_datetime( transactions_df.t_dat )"
      ],
      "metadata": {
        "id": "TPiHTydsD7IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_4w = transactions_df[transactions_df['t_dat'] >= pd.to_datetime('2020-08-24')].copy()\n",
        "df_3w = transactions_df[transactions_df['t_dat'] >= pd.to_datetime('2020-08-31')].copy()\n",
        "df_2w = transactions_df[transactions_df['t_dat'] >= pd.to_datetime('2020-09-07')].copy()\n",
        "df_1w = transactions_df[transactions_df['t_dat'] >= pd.to_datetime('2020-09-15')].copy()"
      ],
      "metadata": {
        "id": "jBAV5Sm8D-Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features[['club_member_status', 'fashion_news_frequency']] = (\n",
        "                   user_features[['club_member_status', 'fashion_news_frequency']]\n",
        "                   .apply(lambda x: pd.factorize(x)[0])\n",
        ").astype('int8')"
      ],
      "metadata": {
        "id": "DJQqqmqUD_0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_df = (\n",
        "    transactions_df\n",
        "    .merge(user_features, on = ('customer_id'))\n",
        "    .merge(item_features, on = ('article_id'))\n",
        ")\n",
        "transactions_df.sort_values(['t_dat', 'customer_id'], inplace=True)"
      ],
      "metadata": {
        "id": "gr4g6jkBEBQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for simplicity let's take only 1M rows\n",
        "N_ROWS = 1_000_000\n",
        "\n",
        "train = transactions_df.loc[ transactions_df.t_dat <= pd.to_datetime('2020-09-15') ].iloc[:N_ROWS]\n",
        "valid = transactions_df.loc[ transactions_df.t_dat >= pd.to_datetime('2020-09-16') ]"
      ],
      "metadata": {
        "id": "YQLp1e3ZEDSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#delete transactions to save memory\n",
        "del transactions_df"
      ],
      "metadata": {
        "id": "L6VNVs-pEEpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, valid.shape"
      ],
      "metadata": {
        "id": "-nDbIHCpEFwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare candidates"
      ],
      "metadata": {
        "id": "eyFezq9WEIBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "purchase_dict_4w = {}\n",
        "\n",
        "for i,x in enumerate(zip(df_4w['customer_id'], df_4w['article_id'])):\n",
        "    cust_id, art_id = x\n",
        "    if cust_id not in purchase_dict_4w:\n",
        "        purchase_dict_4w[cust_id] = {}\n",
        "    \n",
        "    if art_id not in purchase_dict_4w[cust_id]:\n",
        "        purchase_dict_4w[cust_id][art_id] = 0\n",
        "    \n",
        "    purchase_dict_4w[cust_id][art_id] += 1\n",
        "\n",
        "dummy_list_4w = list((df_4w['article_id'].value_counts()).index)[:12]"
      ],
      "metadata": {
        "id": "nl-mFnE9EHhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purchase_dict_3w = {}\n",
        "\n",
        "for i,x in enumerate(zip(df_3w['customer_id'], df_3w['article_id'])):\n",
        "    cust_id, art_id = x\n",
        "    if cust_id not in purchase_dict_3w:\n",
        "        purchase_dict_3w[cust_id] = {}\n",
        "    \n",
        "    if art_id not in purchase_dict_3w[cust_id]:\n",
        "        purchase_dict_3w[cust_id][art_id] = 0\n",
        "    \n",
        "    purchase_dict_3w[cust_id][art_id] += 1\n",
        "\n",
        "dummy_list_3w = list((df_3w['article_id'].value_counts()).index)[:12]"
      ],
      "metadata": {
        "id": "MipiRJEfEPT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purchase_dict_2w = {}\n",
        "\n",
        "for i,x in enumerate(zip(df_2w['customer_id'], df_2w['article_id'])):\n",
        "    cust_id, art_id = x\n",
        "    if cust_id not in purchase_dict_2w:\n",
        "        purchase_dict_2w[cust_id] = {}\n",
        "    \n",
        "    if art_id not in purchase_dict_2w[cust_id]:\n",
        "        purchase_dict_2w[cust_id][art_id] = 0\n",
        "    \n",
        "    purchase_dict_2w[cust_id][art_id] += 1\n",
        "\n",
        "dummy_list_2w = list((df_2w['article_id'].value_counts()).index)[:12]"
      ],
      "metadata": {
        "id": "avgf2HzyERGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purchase_dict_1w = {}\n",
        "\n",
        "for i,x in enumerate(zip(df_1w['customer_id'], df_1w['article_id'])):\n",
        "    cust_id, art_id = x\n",
        "    if cust_id not in purchase_dict_1w:\n",
        "        purchase_dict_1w[cust_id] = {}\n",
        "    \n",
        "    if art_id not in purchase_dict_1w[cust_id]:\n",
        "        purchase_dict_1w[cust_id][art_id] = 0\n",
        "    \n",
        "    purchase_dict_1w[cust_id][art_id] += 1\n",
        "\n",
        "dummy_list_1w = list((df_1w['article_id'].value_counts()).index)[:12]"
      ],
      "metadata": {
        "id": "jaG_tC9VETBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_candidates(customers_id, n_candidates = 12):\n",
        "  \"\"\"\n",
        "  df - basically, dataframe with customers(customers should be unique)\n",
        "  \"\"\"\n",
        "  prediction_dict = {}\n",
        "  dummy_list = list((df_2w['article_id'].value_counts()).index)[:n_candidates]\n",
        "\n",
        "  for i, cust_id in tqdm(enumerate(customers_id)):\n",
        "    # comment this for validation\n",
        "    if cust_id in purchase_dict_1w:\n",
        "        l = sorted((purchase_dict_1w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
        "        l = [y[0] for y in l]\n",
        "        if len(l)>n_candidates:\n",
        "            s = l[:n_candidates]\n",
        "        else:\n",
        "            s = l+dummy_list_1w[:(n_candidates-len(l))]\n",
        "    elif cust_id in purchase_dict_2w:\n",
        "        l = sorted((purchase_dict_2w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
        "        l = [y[0] for y in l]\n",
        "        if len(l)>n_candidates:\n",
        "            s = l[:n_candidates]\n",
        "        else:\n",
        "            s = l+dummy_list_2w[:(n_candidates-len(l))]\n",
        "    elif cust_id in purchase_dict_3w:\n",
        "        l = sorted((purchase_dict_3w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
        "        l = [y[0] for y in l]\n",
        "        if len(l)>n_candidates:\n",
        "            s = l[:n_candidates]\n",
        "        else:\n",
        "            s = l+dummy_list_3w[:(n_candidates-len(l))]\n",
        "    elif cust_id in purchase_dict_4w:\n",
        "        l = sorted((purchase_dict_4w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
        "        l = [y[0] for y in l]\n",
        "        if len(l)>n_candidates:\n",
        "            s = l[:n_candidates]\n",
        "        else:\n",
        "            s = l+dummy_list_4w[:(n_candidates-len(l))]\n",
        "    else:\n",
        "        s = dummy_list\n",
        "    prediction_dict[cust_id] = s\n",
        "\n",
        "  k = list(map(lambda x: x[0], prediction_dict.items()))\n",
        "  v = list(map(lambda x: x[1], prediction_dict.items()))\n",
        "  negatives_df = pd.DataFrame({'customer_id': k, 'negatives': v})\n",
        "  negatives_df = (\n",
        "      negatives_df\n",
        "      .explode('negatives')\n",
        "      .rename(columns = {'negatives': 'article_id'})\n",
        "  )\n",
        "  return negatives_df"
      ],
      "metadata": {
        "id": "rEAnM8jyEWSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model\n"
      ],
      "metadata": {
        "id": "DVv5eTVMEXID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#take only last 15 transactions\n",
        "train['rank'] = range(len(train))\n",
        "train = (\n",
        "    train\n",
        "    .assign(\n",
        "        rn = train.groupby(['customer_id'])['rank']\n",
        "                  .rank(method='first', ascending=False))\n",
        "    .query(\"rn <= 15\")\n",
        "    .drop(columns = ['price', 'sales_channel_id'])\n",
        "    .sort_values(['t_dat', 'customer_id'])\n",
        ")\n",
        "train['label'] = 1\n",
        "\n",
        "del train['rank']\n",
        "del train['rn']\n",
        "\n",
        "valid.sort_values(['t_dat', 'customer_id'], inplace = True)\n"
      ],
      "metadata": {
        "id": "W4YfzID8EYKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_dates = (\n",
        "    train\n",
        "    .groupby('customer_id')['t_dat']\n",
        "    .max()\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "negatives = prepare_candidates(train['customer_id'].unique(), 15)\n",
        "negatives['t_dat'] = negatives['customer_id'].map(last_dates)\n",
        "\n",
        "negatives = (\n",
        "    negatives\n",
        "    .merge(user_features, on = ('customer_id'))\n",
        "    .merge(item_features, on = ('article_id'))\n",
        ")\n",
        "negatives['label'] = 0"
      ],
      "metadata": {
        "id": "qxgod9OoEdZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.concat([train, negatives])\n",
        "train.sort_values(['customer_id', 't_dat'], inplace = True)"
      ],
      "metadata": {
        "id": "75OKlikvEhme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_baskets = train.groupby(['customer_id'])['article_id'].count().values\n",
        "# valid_baskets = valid.groupby(['customer_id'])['article_id'].count().values\n",
        "train_baskets = train.groupby(['customer_id'])['article_id'].count().values"
      ],
      "metadata": {
        "id": "541DK0hPEjkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the GBM Rankder model\n"
      ],
      "metadata": {
        "id": "ylWIOhxfEmXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranker = LGBMRanker(\n",
        "    objective=\"lambdarank\",\n",
        "    metric=\"ndcg\",\n",
        "    boosting_type=\"dart\",\n",
        "    max_depth=7,\n",
        "    n_estimators=300,\n",
        "    importance_type='gain',\n",
        "    verbose=10\n",
        ")"
      ],
      "metadata": {
        "id": "vAg2UhatEqBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranker = ranker.fit(\n",
        "    train.drop(columns = ['t_dat', 'customer_id', 'article_id', 'label']),\n",
        "    train.pop('label'),\n",
        "    group=train_baskets,\n",
        ")"
      ],
      "metadata": {
        "id": "CJRZ8MDjEreh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions"
      ],
      "metadata": {
        "id": "p0npzXIuEu9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')\n"
      ],
      "metadata": {
        "id": "zv09l8urEsQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = prepare_candidates(sample_sub.customer_id.unique(), 12)\n",
        "candidates = (\n",
        "    candidates\n",
        "    .merge(user_features, on = ('customer_id'))\n",
        "    .merge(item_features, on = ('article_id'))\n",
        ")"
      ],
      "metadata": {
        "id": "PV7EEzLpExQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict using batches"
      ],
      "metadata": {
        "id": "ZFDiDkdnE0Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "batch_size = 1_000_000\n",
        "for bucket in tqdm(range(0, len(candidates), batch_size)):\n",
        "  outputs = ranker.predict(\n",
        "      candidates.iloc[bucket: bucket+batch_size]\n",
        "      .drop(columns = ['customer_id', 'article_id'])\n",
        "      )\n",
        "  preds.append(outputs)"
      ],
      "metadata": {
        "id": "1qsSjKVTE1XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.concatenate(preds)\n",
        "candidates['preds'] = preds\n",
        "preds = candidates[['customer_id', 'article_id', 'preds']]\n",
        "preds.sort_values(['customer_id', 'preds'], ascending=False, inplace = True)\n",
        "preds = (\n",
        "    preds\n",
        "    .groupby('customer_id')[['article_id']]\n",
        "    .aggregate(lambda x: x.tolist())\n",
        ")\n",
        "preds['article_id'] = preds['article_id'].apply(lambda x: ' '.join(['0'+str(k) for k in x]))"
      ],
      "metadata": {
        "id": "mtpKdMn0E4J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting results in csv"
      ],
      "metadata": {
        "id": "TwXrKZ5rE-fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = sample_sub[['customer_id']].merge(\n",
        "    preds\n",
        "    .reset_index()\n",
        "    .rename(columns = {'article_id': 'prediction'}), how = 'left')\n",
        "preds['prediction'].fillna(' '.join(['0'+str(art) for art in dummy_list_2w]), inplace = True)"
      ],
      "metadata": {
        "id": "HqoXmqR9E854"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.to_csv('submisssion_ranking.csv', index = False)"
      ],
      "metadata": {
        "id": "VmGfiRH6E-Aa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}